{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# County NAICS Files\n",
    "After running the notebook, delete the python/data_raw folder<br>\n",
    "Zip level not available -> https://api.census.gov/data/2011/cbp/variables.html<br>\n",
    "This notebook is a filtered and edited version of us_econ.ipynb for generating yearly data.<br>\n",
    "For earlier code that generates averaged data aver years please refer us_econ.ipynb.<br>\n",
    "This notebook will start generating data from year 2017.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "import zipfile, io\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "endyear = datetime.date.today().year\n",
    "api_headers = {}\n",
    "api_headers['x-api-key'] = '975f39a54e48438ceebf303d6018e34db212e804'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a relative location to save the data from the request\n",
    "repo_dir = pathlib.Path().cwd()\n",
    "#print(repo_dir)\n",
    "\n",
    "raw_data_dir = repo_dir / 'data_raw'\n",
    "out_data_dir = raw_data_dir / 'BEA_Industry_Factors'\n",
    "    \n",
    "county_data_dir = out_data_dir / 'county_level'\n",
    "if not county_data_dir.exists():\n",
    "    county_data_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state FIPS codes key\n",
    "state_fips = pd.read_csv('../../../us/id_lists/state_fips.csv', usecols=['Name', 'Postal Code', 'FIPS'])\n",
    "state_fips = state_fips.head(50)  # <-- limit to only US states, not teritories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the API call\n",
    "base_url = \"https://api.census.gov/data\"\n",
    "\n",
    "#\n",
    "# NOTE Years Prior to 2012 Currently have a bug when specifying NAICS#### as one of the columns\n",
    "#      - stick to 2012 and later for now\n",
    "#\n",
    "\n",
    "def get_county_cbp(fips, state, years):\n",
    "    count = 0\n",
    "    for year in years:\n",
    "        print(f\"Getting data for state: {state}\\tyear: {year}\")\n",
    "        if year >= 2000 and year <= 2002:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS1997_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url = f\"{base_url}/{year}/cbp?get={columns_to_select}&for=county:*&in=state:{fips:02d}\"\n",
    "        elif year >= 2003 and year <=2007:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2002_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url = f\"{base_url}/{year}/cbp?get={columns_to_select}&for=county:*&in=state:{fips:02d}\"\n",
    "        elif year >= 2008 and year <= 2011:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2007_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url = f\"{base_url}/{year}/cbp?get={columns_to_select}&for=county:*&in=state:{fips:02d}\"\n",
    "        elif year >= 2012 and year <= 2016:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2012,NAICS2012_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url = f\"{base_url}/{year}/cbp?get={columns_to_select}&for=county:*&in=state:{fips:02d}\"\n",
    "        elif year >= 2017:\n",
    "            columns_to_select = \"GEO_ID,NAME,COUNTY,YEAR,NAICS2017,NAICS2017_LABEL,ESTAB,EMP,PAYANN\"\n",
    "            url = f\"{base_url}/{year}/cbp?get={columns_to_select}&for=county:*&in=state:{fips:02d}\"\n",
    "    \n",
    "    \n",
    "        response = r.get(url, headers=api_headers)\n",
    "\n",
    "        with open(county_data_dir / f\"industriesPerCounty_{str.lower(state.replace(' ', ''))}_{year}.csv\",'w') as resultPath:\n",
    "            for line in response.text.strip().split('\\n'):\n",
    "                line=line.replace('[',\"\").replace(']',\"\")\n",
    "                resultPath.write(line + \"\\n\")\n",
    "\n",
    "        print(\"  > Finished CSV for year\"+str(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Years Initialization for data generation\n",
    "startyear = 2017\n",
    "endyear = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in state_fips.FIPS.unique():\n",
    "     state = state_fips.query(f'FIPS=={fips}').values[0][0]\n",
    "     years=range(startyear,endyear)\n",
    "     get_county_cbp(fips, state, years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation\n",
    "This part allows us to manage different Fips level (county/state) and different NAICS level (sector/industry/etc...)  \n",
    "Trick: Getting the NAICS code from all the NAICS files that we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from startyear\n",
    "\n",
    "def load_all_states(bea_data_dir):\n",
    "    \n",
    "    for i in range(startyear,endyear):\n",
    "\n",
    "        x=\"_\"+str(i)\n",
    "        files = [f for f in bea_data_dir.iterdir() if x in f.name]\n",
    "\n",
    "        for f in files:\n",
    "\n",
    "            # variable selection based on census year\n",
    "            naics_str = \"NAICS2012\" if i < 2017 else \"NAICS2017\"\n",
    "            naics_ttl = \"NAICS2012_TTL\" if i < 2017 else \"NAICS2017_LABEL\"\n",
    "            geo_ttl = \"GEO_TTL\" if i < 2017 else \"NAME\"\n",
    "\n",
    "            df = pd.read_csv(f,encoding='latin-1',dtype={naics_str: str})\n",
    "            if 'Unnamed: 11' in df.columns:\n",
    "                df=df.drop(\"Unnamed: 11\", axis=1)\n",
    "            if 'Unnamed: 10' in df.columns:\n",
    "                df=df.drop(\"Unnamed: 10\", axis=1)\n",
    "\n",
    "            # renaming columns so similar data from 2012 census & 2017 census are entered into appropriate columns\n",
    "            df = df.rename(columns={\"fips\": \"id\", naics_str: \"relevant_naics\",\"EMP\":\"emp\",\"PAYANN\":\"payann\",\"ESTAB\":\"estab\", naics_ttl:\"NAICS_TTL\", geo_ttl:\"GEO_TTL\"})\n",
    "            naics_str = \"relevant_naics\"\n",
    "            naics_ttl = \"NAICS_TTL\"\n",
    "            geo_ttl = \"GEO_TTL\"\n",
    "\n",
    "            df['is5'] = df[naics_str].apply(lambda x: 'True' if len(x) == 5 else 'False')\n",
    "\n",
    "            df.loc[(df['is5'] == 'True') & (df[naics_str].apply(lambda v: v[2:3]) == '-'), 'NAICS_Sector'] = df[naics_str]\n",
    "            df.loc[(df['is5'] == 'True') & (df[naics_str].apply(lambda v: v[2:3]) != '-'), 'NAICS_Sector'] = df[naics_str].apply(lambda v: v[:2])\n",
    "            df.loc[(df['is5'] == 'False') , 'NAICS_Sector'] = df[naics_str].apply(lambda v: v[:2])\n",
    "\n",
    "            yield df\n",
    "    \n",
    "df = pd.concat(load_all_states(county_data_dir)).drop(\"is5\", axis=1)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"county\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process FIPS Code\n",
    "FIPS is the federal/census unique ID for each geographic area.  States have 2 digives and counties have 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process FIPS code\n",
    "df['fips'] = df.GEO_ID.apply(lambda GID: GID.split('US')[1])\n",
    "\n",
    "def county_level(df):\n",
    "    return df[df['id'].str.len() == 5]\n",
    "\n",
    "def state_level(df):\n",
    "    return df[df['id'].str.len() == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE If this block is run please delete the generated file before pushing into repo (file size too large)\n",
    "#df.to_csv(\"allll.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns for aggregate df\n",
    "Skipping code block for averaging data for all years from the original us_econ notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = df.rename(columns={\"fips\": \"id\",\"EMP\":\"emp\",\"PAYANN\":\"payann\",\"ESTAB\":\"estab\"})\n",
    "newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data by NAICS Sector\n",
    "\n",
    "NAICS is the North American Industry Classification System. The coarsest level of classification is the *Sector*.\n",
    "\n",
    "The organization of NAICS is as follows:  <-- from [this page](https://www.census.gov/programs-surveys/economic-census/guidance/understanding-naics.html) on census.gov\n",
    "- Sector: 2-digit code\n",
    "    - Subsector: 3-digit code\n",
    "        - Industry Group: 4-digit code\n",
    "            - NAICS Industry: 5-digit code\n",
    "                - National Industry: 6-digit code\n",
    "\n",
    "Start by grouping the data by sector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naics_level(df, naics_level):\n",
    "    return df[df['relevant_naics'].str.len() == naics_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naics_2 = naics_level(newDF, 2).reset_index(drop=True)\n",
    "df_naics_3 = naics_level(newDF, 3).reset_index(drop=True)\n",
    "df_naics_4 = naics_level(newDF, 4).reset_index(drop=True)\n",
    "df_naics_5 = naics_level(newDF, 5).reset_index(drop=True)\n",
    "df_naics_6 = naics_level(newDF, 6).reset_index(drop=True)\n",
    "\n",
    "df_naics_2 = df_naics_2[df_naics_2.relevant_naics != '00']\n",
    "df_naics_3 = df_naics_3[df_naics_3.relevant_naics != '00']\n",
    "df_naics_4 = df_naics_4[df_naics_4.relevant_naics != '00']\n",
    "df_naics_5 = df_naics_5[df_naics_5.relevant_naics != '00']\n",
    "df_naics_6 = df_naics_6[df_naics_6.relevant_naics != '00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s2=state_level(df_naics_2)\n",
    "c2=county_level(df_naics_2)\n",
    "#s3=state_level(df_naics_3)\n",
    "#c3=county_level(df_naics_3)\n",
    "#s4=state_level(df_naics_4)\n",
    "c4=county_level(df_naics_4)\n",
    "#s5=state_level(df_naics_5)\n",
    "#c5=county_level(df_naics_5)\n",
    "s6=state_level(df_naics_6)\n",
    "#c6=county_level(df_naics_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipped the code block for `The statewide data does not include NAICS starting with 1!` from us_econ nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAICS code to name translation\n",
    "Using 2012 naics codes and industries since 2017 naics codes & industries are not available in the current crosswalks data.<br>\n",
    "TODO: Update the 2012 codes with 2017 codes for updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes = pd.read_csv('../../../us/Crosswalk_MasterCrosswalk.csv', usecols=['2012_NAICS_Code', '2012_NAICS_Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes=NAICS_codes.rename(columns={\"2012_NAICS_Code\": \"relevant_naics\", \"2012_NAICS_Industry\": \"industry_detail\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes=NAICS_codes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes=NAICS_codes.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the row for Industries not classified\n",
    "NAICS_codes\n",
    "new_row = {'relevant_naics':99, 'industry_detail':\"Industries not classified\"}\n",
    "\n",
    "#append row to the dataframe\n",
    "NAICS_codes = pd.concat([NAICS_codes, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_codes.to_csv('../../../us/id_lists/industry_ID_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a states json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateFips = pd.read_csv('../../../us/id_lists/state_fips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateFips=stateFips.drop(['Unnamed: 3','Unnamed: 4','Unnamed: 5','Unnamed: 6'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateFips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stateFips.to_json(county_data_dir/'states.json', orient = \"records\", date_format = \"epoch\", double_precision = 10, force_ascii = True, date_unit = \"ms\", default_handler = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making county to fips csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF=c2[['GEO_TTL','id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF['hascomma'] = countyDF['GEO_TTL'].apply(lambda x: 'True' if ',' in x else 'False')\n",
    "countyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF.loc[(countyDF['hascomma'] == 'True'), 'county'] = countyDF.GEO_TTL.apply(lambda GTT: GTT.split(', ')[0])\n",
    "countyDF.loc[(countyDF['hascomma'] == 'True'), 'state'] = countyDF.GEO_TTL.apply(lambda GTT: GTT.split(', ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF=countyDF[['state','county','id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF = countyDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stateFips.rename(columns={\"Name\": \"state\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.drop(\"FIPS\",axis=1)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF = countyDF.merge(stats, on='state', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countyDF = countyDF.rename(columns={\"Postal Code\": \"abvr\"})\n",
    "countyDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the County level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE Code block to generate individual county level files for each county. (Commented because no need of each county files)\n",
    "# states = newDF.state.unique()\n",
    "# #states=[13]\n",
    "\n",
    "# df_naics_6 = df_naics_6.astype({'relevant_naics': 'string'})\n",
    "\n",
    "# a = county_level(df_naics_2)\n",
    "# b = county_level(df_naics_4)\n",
    "# c = county_level(df_naics_6)\n",
    "\n",
    "# for state in states:\n",
    "#     stateName = stateFips.loc[stateFips.FIPS==state,\"Postal Code\"].values[0]\n",
    "#     print(stateName)\n",
    "\n",
    "#     repo_dir = pathlib.Path().cwd()\n",
    "#     state_dir = repo_dir.parents[2] / 'us' / 'state-naics-update' / stateName\n",
    "    \n",
    "#     if not state_dir.exists():\n",
    "#         state_dir.mkdir(parents=True)\n",
    "    \n",
    "#     a1 = a[a.state==state]\n",
    "#     b1 = b[b.state==state]\n",
    "#     c1 = c[c.state==state]\n",
    "\n",
    "#     for year in range(startyear, endyear):\n",
    "#         print(year)\n",
    "\n",
    "#         a1y = a1[a1.YEAR==year]\n",
    "#         b1y = b1[b1.YEAR==year]\n",
    "#         c1y = c1[c1.YEAR==year]\n",
    "\n",
    "#         def save_county_data(state, df, counties, naics_level_str):\n",
    "#             for county in counties:\n",
    "\n",
    "#                 curr_df = df[df.COUNTY==county]\n",
    "                \n",
    "#                 county = str(county)\n",
    "#                 # print(county)\n",
    "#                 if len(county) == 2:\n",
    "#                     county = \"0\" + county\n",
    "#                 elif len(county) == 1:\n",
    "#                     county = \"00\" + county\n",
    "\n",
    "#                 state = str(state) if len(str(state)) == 2 else \"0\" + str(state)\n",
    "\n",
    "#                 curr_df = curr_df.drop([\"GEO_ID\", \"GEO_TTL\", \"COUNTY\", \"YEAR\", \"NAICS_TTL\", \"state\", \"NAICS_Sector\"], axis=1)\n",
    "#                 curr_df = curr_df.rename(columns={\"id\":\"fips\"})\n",
    "\n",
    "#                 filename = \"US\" + state + county + \"-\" + \"census-\" + naics_level_str + \"-\" + str(year) + \".csv\"\n",
    "\n",
    "#                 curr_df.to_csv(f\"../../../us/state-naics-update/{stateName}/{filename}\")\n",
    "\n",
    "#         c_a1 = a1.COUNTY.unique()\n",
    "#         c_b1 = b1.COUNTY.unique()\n",
    "#         c_c1 = c1.COUNTY.unique()\n",
    "\n",
    "#         save_county_data(state, a1y, c_a1, \"naics2\")\n",
    "#         save_county_data(state, b1y, c_b1, \"naics4\")\n",
    "#         save_county_data(state, c1y, c_c1, \"naics6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = newDF.state.unique()\n",
    "#states=[13]\n",
    "\n",
    "df_naics_6 = df_naics_6.astype({'relevant_naics': 'string'})\n",
    "\n",
    "a = county_level(df_naics_2)\n",
    "b = county_level(df_naics_4)\n",
    "c = county_level(df_naics_6)\n",
    "\n",
    "for state in states:\n",
    "    stateName = stateFips.loc[stateFips.FIPS==state,\"Postal Code\"].values[0]\n",
    "    print(stateName)\n",
    "\n",
    "    repo_dir = pathlib.Path().cwd()\n",
    "    state_dir = repo_dir.parents[2] / 'us' / 'state-naics-update' / stateName\n",
    "    \n",
    "    if not state_dir.exists():\n",
    "        state_dir.mkdir(parents=True)\n",
    "    \n",
    "    a1 = a[a.state==state]\n",
    "    b1 = b[b.state==state]\n",
    "    c1 = c[c.state==state]\n",
    "\n",
    "    for year in range(startyear, endyear):\n",
    "        print(year)\n",
    "\n",
    "        a1y = a1[a1.YEAR==year]\n",
    "        b1y = b1[b1.YEAR==year]\n",
    "        c1y = c1[c1.YEAR==year]\n",
    "\n",
    "        def save_county_data(state, df, naics_level_str):\n",
    "\n",
    "            state = str(state) if len(str(state)) == 2 else \"0\" + str(state)\n",
    "\n",
    "            curr_df = curr_df.drop([\"GEO_ID\", \"GEO_TTL\", \"COUNTY\", \"YEAR\", \"NAICS_TTL\", \"state\", \"NAICS_Sector\"], axis=1)\n",
    "            curr_df = curr_df.rename(columns={\"id\":\"fips\", \"relevant_naics\":\"Naics\", \"estab\":\"Establishments\", \"emp\":\"Employees\", \"payann\":\"Payroll\"})\n",
    "\n",
    "            filename = \"US\" + stateName + \"-\" + \"census-\" + naics_level_str + \"-\" + str(year) + \".csv\"\n",
    "\n",
    "            curr_df.to_csv(f\"../../../us/state-naics-update/{stateName}/{filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the statewide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=newDF.state.unique()\n",
    "#states=[13]\n",
    "\n",
    "for state in states:\n",
    "    \n",
    "    b1 = county_level(df_naics_2)\n",
    "    c1 = b1[b1.state==state]\n",
    "    c1.astype({'NAICS_Sector': 'int'})\n",
    "    d1 = c1.groupby(['NAICS_Sector','NAICS_TTL','state','relevant_naics', \"YEAR\"],as_index=False).sum()\n",
    "    d1 = d1.drop([\"COUNTY\",\"id\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\", \"GEO_ID\"],axis=1)\n",
    "    d1.insert(0, 'fips', state)\n",
    "    # d1.insert(1, 'COUNTY', 999)\n",
    "    # d1.insert(2, 'GEO_TTL', 'Statewide')\n",
    "\n",
    "    b2 = county_level(df_naics_4)\n",
    "    c2 = b2[b2.state==state]\n",
    "    c2.astype({'NAICS_Sector': 'int'})\n",
    "    d2 = c2.groupby(['NAICS_Sector','NAICS_TTL','state','relevant_naics', \"YEAR\"],as_index=False).sum()\n",
    "    d2 = d2.drop([\"COUNTY\",\"id\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\", \"GEO_ID\"],axis=1)\n",
    "    d2.insert(0, 'fips', state)\n",
    "    # d2.insert(1, 'COUNTY', 999)\n",
    "    # d2.insert(2, 'GEO_TTL', 'Statewide')\n",
    "\n",
    "    b3 = county_level(df_naics_6)\n",
    "    c3 = b3[b3.state==state]\n",
    "    c3.astype({'NAICS_Sector': 'int'})\n",
    "    d3 = c3.groupby(['NAICS_Sector','NAICS_TTL','state','relevant_naics', \"YEAR\"],as_index=False).sum()\n",
    "    d3 = d3.drop([\"COUNTY\",\"id\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\", \"GEO_ID\"],axis=1)\n",
    "    d3.insert(0, 'fips', state)\n",
    "    # d3.insert(1, 'COUNTY', 999)\n",
    "    # d3.insert(2, 'GEO_TTL', 'Statewide')\n",
    "    \n",
    "    stateName=stateFips.loc[stateFips.FIPS==state,\"Postal Code\"].values[0]\n",
    "    print(stateName)\n",
    "\n",
    "    for year in range(startyear, endyear):\n",
    "        print(year)\n",
    "\n",
    "        def save_state_data(state, df, naics_level_str):\n",
    "                \n",
    "            state = str(state) if len(str(state)) == 2 else \"0\" + str(state)\n",
    "\n",
    "            filename = \"US\" + state + \"-\" + \"census-\" + naics_level_str + \"-\" + str(year) + \".csv\"\n",
    "\n",
    "            df.to_csv(f\"../../../us/state-naics-update/{stateName}/{filename}\")\n",
    "\n",
    "        d1y = d1[d1.YEAR==year]\n",
    "        d2y = d2[d2.YEAR==year]\n",
    "        d3y = d3[d3.YEAR==year]\n",
    "\n",
    "        d1y = d1y.drop([\"YEAR\"],axis=1)\n",
    "        d2y = d2y.drop([\"YEAR\"],axis=1)\n",
    "        d3y = d3y.drop([\"YEAR\"],axis=1)\n",
    "\n",
    "        save_state_data(state, d1y, \"naics2\")\n",
    "        save_state_data(state, d2y, \"naics4\")\n",
    "        save_state_data(state, d3y, \"naics6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statewide data from API, The correct version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_data_dir = out_data_dir / 'state_level'\n",
    "if not state_data_dir.exists():\n",
    "    state_data_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for the API call\n",
    "base_url = \"https://api.census.gov/data\"\n",
    "\n",
    "#\n",
    "# NOTE Years Prior to 2012 Currently have a bug when specifying NAICS#### as one of the columns\n",
    "#      - stick to 2012 and later for now\n",
    "#\n",
    "\n",
    "def get_state_cbp(fips, state, years):\n",
    "    count=0\n",
    "    for year in years:\n",
    "        print(f\"Getting data for state: {state}\\tyear: {year}\")\n",
    "        if year>=2000 and year<=2002:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS1997_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url=f\"{base_url}/{year}/cbp?get={columns_to_select}&for=state:{fips:02d}\"\n",
    "        elif year>=2003 and year<=2007:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2002_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url=f\"{base_url}/{year}/cbp?get={columns_to_select}&for=state:{fips:02d}\"\n",
    "        elif year>=2008 and year<=2011:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2007_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url=f\"{base_url}/{year}/cbp?get={columns_to_select}&for=state:{fips:02d}\"\n",
    "        elif year>=2012 and year<=2016:\n",
    "            columns_to_select = \"GEO_ID,GEO_TTL,COUNTY,YEAR,NAICS2012,NAICS2012_TTL,ESTAB,EMP,PAYANN\"\n",
    "            url=f\"{base_url}/{year}/cbp?get={columns_to_select}&for=state:{fips:02d}\"\n",
    "        elif year>=2017 and year <= 2021:\n",
    "            columns_to_select = \"GEO_ID,NAME,COUNTY,YEAR,NAICS2017,NAICS2017_LABEL,ESTAB,EMP,PAYANN\"\n",
    "            url=f\"{base_url}/{year}/cbp?get={columns_to_select}&for=state:{fips:02d}\"\n",
    "    \n",
    "    \n",
    "        response = r.get(url, headers=api_headers)\n",
    "\n",
    "        with open(state_data_dir / f\"industriesPerState_{str.lower(state.replace(' ', ''))}_{year}.csv\",'w') as resultPath:\n",
    "            for line in response.text.strip().split('\\n'):\n",
    "                line=line.replace('[',\"\").replace(']',\"\")\n",
    "                resultPath.write(line + \"\\n\")\n",
    "\n",
    "        print(\"  > Finished CSV for year\"+str(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in state_fips.FIPS.unique():\n",
    "     state = state_fips.query(f'FIPS=={fips}').values[0][0]\n",
    "     years=range(startyear,endyear)\n",
    "     get_state_cbp(fips, state, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state = pd.concat(load_all_states(state_data_dir)).drop(\"is5\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state['fips'] = df_state.GEO_ID.apply(lambda GID: GID.split('US')[1])\n",
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state[\"COUNTY\"] = 0\n",
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_str = \"relevant_naics\"\n",
    "naics_ttl = \"NAICS_TTL\"\n",
    "geo_ttl = \"GEO_TTL\"\n",
    "\n",
    "newDF_state = df_state.filter(['fips', 'state', 'COUNTY', 'YEAR' ,geo_ttl, naics_str, naics_ttl,'NAICS_Sector', \"estab\", \"emp\", \"payann\"], axis=1)\n",
    "newDF_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naics_2_state = naics_level(newDF_state, 2).reset_index(drop=True)\n",
    "df_naics_3_state = naics_level(newDF_state, 3).reset_index(drop=True)\n",
    "df_naics_4_state = naics_level(newDF_state, 4).reset_index(drop=True)\n",
    "df_naics_5_state = naics_level(newDF_state, 5).reset_index(drop=True)\n",
    "df_naics_6_state = naics_level(newDF_state, 6).reset_index(drop=True)\n",
    "\n",
    "df_naics_2_state = df_naics_2_state[df_naics_2_state.relevant_naics != '00']\n",
    "df_naics_3_state = df_naics_3_state[df_naics_3_state.relevant_naics != '00']\n",
    "df_naics_4_state = df_naics_4_state[df_naics_4_state.relevant_naics != '00']\n",
    "df_naics_5_state = df_naics_5_state[df_naics_5_state.relevant_naics != '00']\n",
    "df_naics_6_state = df_naics_6_state[df_naics_6_state.relevant_naics != '00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naics_2_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states=newDF.state.unique()\n",
    "\n",
    "a = df_naics_2_state\n",
    "b = df_naics_4_state\n",
    "c = df_naics_6_state\n",
    "for state in states:\n",
    "    stateName=stateFips.loc[stateFips.FIPS==state,\"Postal Code\"].values[0]\n",
    "    print(stateName)\n",
    "\n",
    "    a1 = a[a.state==state]\n",
    "    b1 = b[b.state==state]\n",
    "    c1 = c[c.state==state]\n",
    "\n",
    "    a1 = a1.drop([\"COUNTY\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\"],axis=1)\n",
    "    b1 = b1.drop([\"COUNTY\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\"],axis=1)\n",
    "    c1 = c1.drop([\"COUNTY\", \"GEO_TTL\", \"NAICS_Sector\", \"NAICS_TTL\", \"state\"],axis=1)\n",
    "\n",
    "\n",
    "    repo_dir = pathlib.Path().cwd()\n",
    "    state_dir = repo_dir.parents[2] / 'us' / 'state-naics-update' / stateName / 'state-naics-api'\n",
    "    \n",
    "    if not state_dir.exists():\n",
    "        state_dir.mkdir(parents=True)\n",
    "\n",
    "    for year in range(startyear, endyear):\n",
    "        \n",
    "        ay = a1[a1.YEAR==year]\n",
    "        by = b1[b1.YEAR==year]\n",
    "        cy = c1[c1.YEAR==year]\n",
    "\n",
    "        ay = ay.drop([\"YEAR\"],axis=1)\n",
    "        by = by.drop([\"YEAR\"],axis=1)\n",
    "        cy = cy.drop([\"YEAR\"],axis=1)\n",
    "\n",
    "        def save_state_data(state, df, naics_level_str):\n",
    "                \n",
    "            state = str(state) if len(str(state)) == 2 else \"0\" + str(state)\n",
    "\n",
    "            filename = \"US\" + state + \"-\" + \"census-\" + naics_level_str + \"-\" + str(year) + \".csv\"\n",
    "\n",
    "            df.to_csv(f\"../../../us/state-naics-update/{stateName}/state-naics-api/{filename}\")\n",
    "\n",
    "        save_state_data(state, ay, \"naics2\")\n",
    "        save_state_data(state, by, \"naics4\")\n",
    "        save_state_data(state, cy, \"naics6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
